*** md.h	2009-10-02 02:46:43.000000000 +0800
--- ../st-1.9-patch/md.h	2018-11-04 18:21:53.000000000 +0800
***************
*** 420,432 ****
  
  #elif defined(__arm__)
  #define MD_STACK_GROWS_DOWN
  
  #if defined(__GLIBC__) && __GLIBC__ >= 2
! #define MD_GET_SP(_t) (_t)->context[0].__jmpbuf[20]
  #else
  #error "ARM/Linux pre-glibc2 not supported yet"
  #endif /* defined(__GLIBC__) && __GLIBC__ >= 2 */
  
  #elif defined(__s390__)
  #define MD_STACK_GROWS_DOWN
  
--- 420,439 ----
  
  #elif defined(__arm__)
  #define MD_STACK_GROWS_DOWN
+ #define MD_USE_BUILTIN_SETJMP
  
  #if defined(__GLIBC__) && __GLIBC__ >= 2
! #define MD_GET_SP(_t) (_t)->context[0].__jmpbuf[8]
  #else
  #error "ARM/Linux pre-glibc2 not supported yet"
  #endif /* defined(__GLIBC__) && __GLIBC__ >= 2 */
  
+ #elif defined(__aarch64__)
+ #define MD_STACK_GROWS_DOWN
+ #define MD_USE_BUILTIN_SETJMP
+ 
+ #define MD_GET_SP(_t) (_t)->context[0].__jmpbuf[13]
+ 
  #elif defined(__s390__)
  #define MD_STACK_GROWS_DOWN
  
*** md.S	2006-05-05 14:03:02.000000000 +0800
--- ../st-1.9-patch/md.S	2018-12-09 09:16:54.000000000 +0800
***************
*** 427,431 ****
--- 427,592 ----
  
  /****************************************************************/
  
+ #elif defined(__arm__)
+ 
+ /* Register list for a ldm/stm instruction to load/store
+    the general registers from a __jmp_buf.  */
+ # define JMP_BUF_REGLIST	{v1-v6, sl, fp, sp, lr}
+ 
+ 	.file "md.S"
+ 	.text
+ 
+ 	/* _st_md_cxt_save(__jmp_buf env) */
+ 	.globl _st_md_cxt_save
+ 	.type _st_md_cxt_save, %function
+ 	.align 2
+ _st_md_cxt_save:
+ 	mov	ip, r0
+ 
+ 	/* Save registers */
+ 	stmia	ip!, JMP_BUF_REGLIST
+ 
+ #ifdef __VFP_FP__
+ 	/* Store the VFP registers.  */
+ 	/* Following instruction is vstmia ip!, {d8-d15}.  */
+ 	stc	p11, cr8, [ip], #64
+ #endif
+ 
+ #ifdef __IWMMXT__
+ 	/* Save the call-preserved iWMMXt registers.  */
+ 	/* Following instructions are wstrd wr10, [ip], #8 (etc.)  */
+ 	stcl	p1, cr10, [r12], #8
+ 	stcl	p1, cr11, [r12], #8
+ 	stcl	p1, cr12, [r12], #8
+ 	stcl	p1, cr13, [r12], #8
+ 	stcl	p1, cr14, [r12], #8
+ 	stcl	p1, cr15, [r12], #8
+ #endif
+ 
+ 	mov	r0, #0
+ 	bx	lr 
+ 
+ 	.size _st_md_cxt_save, .-_st_md_cxt_save
+ 
+ /****************************************************************/
+ 
+ 	/* _st_md_cxt_restore(__jmp_buf env, int val) */
+ 	.globl _st_md_cxt_restore
+ 	.type _st_md_cxt_restore, %function
+ 	.align 2
+ _st_md_cxt_restore:
+ 	mov	ip, r0
+ 
+ 	/* Restore registers */
+ 	ldmia	ip!, JMP_BUF_REGLIST
+ 
+ #ifdef __VFP_FP__
+ 	/* Restore the VFP registers.  */
+ 	/* Following instruction is vldmia ip!, {d8-d15}.  */
+ 	ldc	p11, cr8, [r12], #64
+ #endif
+ 
+ #ifdef __IWMMXT__
+ 	/* Restore the call-preserved iWMMXt registers.  */
+ 	/* Following instructions are wldrd wr10, [ip], #8 (etc.)  */
+ 	ldcl	p1, cr10, [r12], #8
+ 	ldcl	p1, cr11, [r12], #8
+ 	ldcl	p1, cr12, [r12], #8
+ 	ldcl	p1, cr13, [r12], #8
+ 	ldcl	p1, cr14, [r12], #8
+ 	ldcl	p1, cr15, [r12], #8
+ #endif
+ 
+ 	movs	r0, r1		/* get the return value in place */
+ 	moveq	r0, #1		/* can't let setjmp() return zero! */
+ 	bx	lr
+ 
+ 	.size _st_md_cxt_restore, .-_st_md_cxt_restore
+ 
+ /****************************************************************/
+ 
+ #elif defined(__aarch64__)
+ 
+ #define JB_X19            0
+ #define JB_X20            1
+ #define JB_X21            2
+ #define JB_X22            3
+ #define JB_X23            4
+ #define JB_X24            5
+ #define JB_X25            6
+ #define JB_X26            7
+ #define JB_X27            8
+ #define JB_X28            9
+ #define JB_X29           10
+ #define JB_LR            11
+ #define JB_SP		 13
+ 
+ #define JB_D8		 14
+ #define JB_D9		 15
+ #define JB_D10		 16
+ #define JB_D11		 17
+ #define JB_D12		 18
+ #define JB_D13		 19
+ #define JB_D14		 20
+ #define JB_D15		 21
+ 
+ 	.file "md.S"
+ 	.text
+ 
+ 	/* _st_md_cxt_save(__jmp_buf env) */
+ 	.globl _st_md_cxt_save
+ 	.type _st_md_cxt_save, %function
+ 	.align 4
+ _st_md_cxt_save:
+ 	stp	x19, x20, [x0, #JB_X19<<3]
+ 	stp	x21, x22, [x0, #JB_X21<<3]
+ 	stp	x23, x24, [x0, #JB_X23<<3]
+ 	stp	x25, x26, [x0, #JB_X25<<3]
+ 	stp	x27, x28, [x0, #JB_X27<<3]
+ 	stp	x29, x30, [x0, #JB_X29<<3]
+ 
+ 	stp	 d8,  d9, [x0, #JB_D8<<3]
+ 	stp	d10, d11, [x0, #JB_D10<<3]
+ 	stp	d12, d13, [x0, #JB_D12<<3]
+ 	stp	d14, d15, [x0, #JB_D14<<3]
+ 	mov	x2,  sp
+ 	str	x2,  [x0, #JB_SP<<3]
+ 
+ 	mov	x0, #0
+ 	ret
+ 	.size _st_md_cxt_save, .-_st_md_cxt_save
+ 
+ /****************************************************************/
+ 
+ 	/* _st_md_cxt_restore(__jmp_buf env, int val) */
+ 	.globl _st_md_cxt_restore
+ 	.type _st_md_cxt_restore, %function
+ 	.align 4
+ _st_md_cxt_restore:
+ 	ldp	x19, x20, [x0, #JB_X19<<3]
+ 	ldp	x21, x22, [x0, #JB_X21<<3]
+ 	ldp	x23, x24, [x0, #JB_X23<<3]
+ 	ldp	x25, x26, [x0, #JB_X25<<3]
+ 	ldp	x27, x28, [x0, #JB_X27<<3]
+ 
+ 	ldp	x29, x30, [x0, #JB_X29<<3]
+ 
+ 	ldp	 d8,  d9, [x0, #JB_D8<<3]
+ 	ldp	d10, d11, [x0, #JB_D10<<3]
+ 	ldp	d12, d13, [x0, #JB_D12<<3]
+ 	ldp	d14, d15, [x0, #JB_D14<<3]
+ 
+ 	ldr	x5, [x0, #JB_SP<<3]
+ 	mov	sp, x5
+ 
+ 	cmp	x1, #0
+ 	mov	x0, #1
+ 	csel	x0, x1, x0, ne
+ 	/* Use br instead of ret because ret is guaranteed to mispredict */
+ 	br	x30
+ 	.size _st_md_cxt_restore, .-_st_md_cxt_restore
+ 
+ /****************************************************************/
+ 
  #endif
  
